
二年以上工作经验
性别：
女 
年龄：
31岁
居住地：
河南
电话：
137*******(手机) 
E-mail：
luliuna@51job.com
###
学校：
兰州理工大学
学历：
本科
专业：
植物生物技术
###
大学英语四级
2011/12
###
2016年-2017年      SRT项目  项目负责人  
课题：
项目描述：实验过程中通过小球藻高速生长处理沼液废水同时提升沼气为主要研究目标，采用多种                手段进行效率控制。
工作职责：
工作业绩：
20xx年      xxxxxx项目  项目组成员
课题：xxxxxxxx
项目描述：
工作职责;
工作业绩：
###
大学英语四级
2009/6
###
Atlas二次开发及优化：提升Atlas读写性能和bug修复，Atlas元数据写入速度提升6倍以上，向社区贡献patch 5个，主要工作包括：
修复Atlas创建全文索引时错误地遍历所有related entity的bug，将时间复杂度O(n^2)降低为O(n)。
解决Atlas生成重复血缘信息的问题，主要方案包括：查询血缘数据的gremlin query支持根据数据节点状态(deleted/active)过滤；血缘唯一性标识与工作流信息绑定。
结合Jstack和Arthas排查Atlas连接远程Hbase时读写性能下降超过70%的问题，通过开启JanusGraph的Batch-loading模式和降低ping延时解决。
工作流调度引擎系统（2019.7-至今，接手开发任务和日常运维）
基于Apache Oozie进行二次开发，支持对Java、Shell、Hive、Spark等类型任务的工作流编排和定时调度。我负责的主要开发工作包括：
支持对公司自研Sql引擎的工作流调度，具体功能点包括：
支持sql提交、任务状态检查等基础功能；并通过解析日志获取action关联的application_id，根据application_id进行任务杀死和日志获取。
支持根据指定比例的Hive任务切换到自研Sql引擎执行，实现灰度切换。
任务总体失败率监控，定期采样当前失败率并投递到监控平台。
支持工作流节点执行前检查所依赖的数据是否生成完毕，具体功能点包括：
支持根据指定资源路径来检查任务所依赖的数据是否生产完毕。
支持指定检查操作的超时时间，在时间阈值内定时重新检查。
Oozie工作流配置文件双写HDFS和OSS，避免HDFS故障导致Oozie不可用：
提交工作流文件时以同步模式写入OSS，通过kafka异步通知HDFS从OSS拉取文件。
读取工作流文件时优先从OSS获取，失败后切换到从HDFS拉取文件。
根据文件内容长度定时进行全量/增量检查HDFS和OSS的数据一致性。
###
大学英语四级
2011/12
